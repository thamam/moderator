# BMAD Backend Integration Guide for Moderator

**BMAD (Breakthrough Method of Agile AI-Driven Development) operates fundamentally differently from traditional backend engines.** Rather than a Python library with direct imports, BMAD is a Node.js-based methodology framework that integrates with Python systems through the Model Context Protocol (MCP) server pattern. This comprehensive guide provides everything needed to implement BMAD as a Moderator backend adapter, including architecture analysis, integration patterns, complete code examples, and practical migration strategies from CCPM and Claude Code.

## Understanding BMAD's revolutionary approach

BMAD solves the two most critical problems in AI-assisted development: **planning inconsistency** and **context loss**. Unlike traditional tools that rely on conversational interactions prone to context degradation, BMAD implements an "agent-as-code" paradigm where specialized AI agents function as a complete agile team. The Analyst, Product Manager, Architect, UX Expert, Scrum Master, Developer, and QA agents collaborate through structured workflows, with each agent defined as a self-contained Markdown file containing embedded YAML configuration. This architecture transforms chaotic "vibe coding" into systematic, repeatable processes.

The framework operates in two distinct phases optimized for different contexts. **Phase 1: Agentic Planning** runs in high-context web environments (Gemini, ChatGPT, Claude) where planning agents collaborate with humans to create comprehensive Product Requirements Documents, system architectures, and UX specifications. **Phase 2: Context-Engineered Development** executes in local IDEs where the Scrum Master generates hyper-detailed story files containing complete implementation context, enabling Developer agents to work without external references or context loss. Each story file becomes a self-contained artifact with requirements, architectural guidance, implementation details, and historical context from previous stories.

BMAD version 4.43.1 is production-ready with 10,100 GitHub stars and active community support through Discord. The framework is distributed via NPM and supports 15+ IDEs including Cursor, Claude Code, Windsurf, VS Code extensions, and CLI tools. MIT-licensed and tool-agnostic, BMAD works across multiple AI models and platforms, with expansion packs extending functionality beyond software development to game development, creative writing, DevOps, and business strategy.

## Installation and environment setup

Installing BMAD requires Node.js v20+ as the foundational runtime. The recommended installation method uses NPX for direct execution without global installation overhead. Run `npx bmad-method install` in your project directory, which launches an interactive installer that detects existing installations, creates the `.bmad-core` directory structure, configures IDE-specific integrations, and generates web bundles for the planning phase. The installer supports multiple IDEs simultaneously and automatically handles upgrades by updating only changed files while preserving customizations with `.bak` backups.

For development or customization, clone the repository with `git clone https://github.com/bmad-code-org/BMAD-METHOD.git`, navigate to the directory, install dependencies with `npm install`, and run the local installer using `npm run install:bmad`. Global installation via `npm install -g bmad-method` enables the `bmad` command directly, though NPX execution remains the community-recommended approach for reproducibility. The installation creates agent definitions in `.bmad-core/agents/`, executable tasks in `.bmad-core/tasks/`, document templates in `.bmad-core/templates/`, and central configuration in `.bmad-core/core-config.yaml`.

Environment configuration differs significantly from traditional backend engines because **BMAD does not require API keys or authentication for core functionality**. The framework itself is a methodology layer; AI model credentials are configured in your chosen IDE or platform. For MCP server integration with Python, create a `.env` file with `OPENROUTER_API_KEY` or your preferred model provider's credentials, `BMAD_MAX_DAILY_HOURS` for project tracking, `BMAD_DEFAULT_AGENT` to specify the primary agent (typically "dev"), and `PYTHONPATH` pointing to your MCP server implementation. Set `PYTHONIOENCODING=utf-8` and `PYTHONUNBUFFERED=1` for proper subprocess communication.

The project structure after installation centers around `.bmad-core/` containing all framework files, `docs/` for generated artifacts including PRDs, architecture documents, epic shards, story files, and QA assessments, and IDE-specific configuration files like `.cursor/rules/bmad/` for Cursor integration or `.claude/commands/BMad/` for Claude Code. Each agent is defined in a complete Markdown file with embedded YAML, making the system version-controllable and portable. The `core-config.yaml` file controls document locations, agent behavior, and dev agent context loading, providing flexibility to adapt BMAD to existing project structures rather than forcing migrations.

## Architecture and methodology deep dive

BMAD's agent-as-code paradigm treats agents as configuration artifacts rather than platform-specific setups, mirroring Infrastructure-as-Code principles. Each agent exists as a self-contained Markdown file with a YAML configuration block defining identity (name, role, icon), persona (style, focus, core principles), commands (with `*` prefix like `*create-prd`, `*implement-story`), and dependencies (templates, tasks, checklists, data files). The framework implements **lazy loading** where dependencies are resolved only when commands execute, minimizing context consumption and maximizing efficiency. Agents operate in complete isolation with no shared memory or context—users must manually relay information between agents, effectively becoming the workflow orchestrator.

The execution model follows a sophisticated two-phase workflow. During Agentic Planning, the Analyst agent facilitates brainstorming sessions to create project briefs, the PM agent transforms briefs into detailed PRDs with epics and user stories, the Architect agent designs comprehensive system architecture with tech stack decisions and security patterns, the UX Expert creates front-end specifications, and the Product Owner validates alignment between requirements and design. These planning agents work in high-context environments where 200K+ token windows enable comprehensive analysis and iterative refinement with human-in-the-loop feedback.

Context-Engineered Development represents BMAD's most innovative contribution to AI-assisted coding. The Scrum Master agent reads the sharded PRD and Architecture documents to generate story files at `docs/stories/{epicNum}.{storyNum}.story.md`, embedding complete context including functional requirements from the PRD, architectural guidance from design documents, implementation details and file references, acceptance criteria for testing, and development notes from previous stories. This **hyper-detailed story approach eliminates context loss** because Developer agents open story files with everything needed to implement features correctly without searching documentation or re-explaining requirements across sessions.

The workflow continues with the Developer agent implementing stories by loading `devLoadAlwaysFiles` from core-config (typically coding standards, tech stack preferences, project structure), reading the complete story file, writing code incrementally with tests, running validation suites, and marking stories "Ready for Review". The QA agent then performs comprehensive assessments including risk analysis for high-complexity changes, test design planning before implementation, requirements traceability mapping, non-functional requirements validation, and code review with refactoring suggestions. Quality gates track pass/advisory/blocked statuses, ensuring systematic verification at every step. Story states progress from Draft → In Progress → Ready for Review → In Review → Done, with sequential enforcement preventing agents from jumping ahead without foundational work completed.

## Core configuration schema and examples

The `core-config.yaml` file in `.bmad-core/` serves as the central nervous system for BMAD behavior. The configuration uses YAML format with sections for QA (`qaLocation: docs/qa`), PRD structure (`prdVersion: v4`, `prdSharded: true`, `prdShardedLocation: docs/epics`, `epicFilePattern: epic-{n}*.md`), Architecture layout (`architectureVersion: v4`, `architectureSharded: true`, `architectureShardedLocation: docs/architecture`), and Developer settings (`devLoadAlwaysFiles` array, `devDebugLog: docs/dev-debug.log`, `devStoryLocation: docs/stories`). The agent section specifies `agentCoreDump: docs/agent-dumps` for debugging and troubleshooting.

Document sharding configuration controls how BMAD breaks large files into manageable pieces. Setting `prdSharded: true` with `prdShardedLocation: docs/epics` tells agents to look for epic-specific files rather than a monolithic PRD, dramatically improving focus and reducing hallucination. Similarly, `architectureSharded: true` with `architectureShardedLocation: docs/architecture` enables component-focused architecture documents. The `epicFilePattern` supports flexible naming conventions, though the default implementation sometimes hardcodes patterns causing filename inconsistencies users must manually work around.

The `devLoadAlwaysFiles` configuration is **critical for Developer agent effectiveness**. This array specifies documents loaded into context for every Dev agent session, typically including `docs/architecture/coding-standards.md` for consistent code style, `docs/architecture/tech-stack.md` for technology decisions, and `docs/architecture/project-structure.md` for file organization patterns. Adding security guidelines, API specifications, or domain-specific knowledge bases here ensures developers have essential context without embedding everything in story files. Keep these files under 10KB each to avoid context window bloat.

Agent definitions use a consistent structure across all agent types. The YAML block specifies `agent.id` (short identifier), `agent.name` (human-readable), `agent.icon` (emoji for UI), `agent.role` (description), and `agent.when-to-use` (guidance). The persona section defines `style`, `identity`, `focus` array, and `core-principles` array to shape agent behavior and communication patterns. Commands list available operations with descriptions and task references. Dependencies declare required templates (YAML document generators), tasks (procedural workflows), checklists (validation lists), and data (knowledge bases). This modular dependency resolution enables agents to be self-contained while sharing common resources.

Template files in `.bmad-core/templates/` use YAML structure to define document generation. The prd-template.yaml includes metadata (version, created date, project name), sections array with title and instruction for each (Executive Summary, Functional Requirements, Non-Functional Requirements, Epics), and subsection definitions with field specifications. Story templates follow similar patterns with frontmatter (story number, epic, title, status), section definitions (Overview, Acceptance Criteria, Dev Notes, QA Notes), and placeholder variables for dynamic content. Templates transform agent prompts into consistent, structured documentation that subsequent agents can reliably parse and utilize.

## Python integration through MCP servers

**BMAD cannot be imported as a Python library**—this is the most critical fact for Moderator integration. Instead, integration happens through the Model Context Protocol (MCP), a standardized interface enabling AI assistants to interact with external tools and data sources. MCP servers expose functions as tools (like POST endpoints), resources as read-only data (like GET endpoints), prompts as reusable templates, and context as server metadata. Python MCP servers act as adapters between BMAD's Node.js methodology framework and Python-based orchestration systems like Moderator.

Setting up a Python MCP server begins with installing FastMCP (`pip install fastmcp`) or the Python MCP SDK (`pip install mcp`). Create `server.py` importing FastMCP and initializing with `mcp = FastMCP(name="BMAD Server")`. Define tools using the `@mcp.tool()` decorator—for example, `create_task(task_id: str, name: str, allocated_hours: float, agent: str = "dev") -> dict` creates BMAD tasks, `update_task_progress(task_id: str, hours_completed: float) -> dict` tracks implementation progress, and `list_agents() -> list` returns available BMAD agents. Define resources with `@mcp.resource("bmad://config")` to expose configuration data like version, available agents, and maximum hours. Run the server with `mcp.run()` for STDIO transport (local/IDE integration) or `mcp.run(transport="sse", port=8000)` for web deployment.

Subprocess execution provides the primary pattern for Python-to-BMAD communication. Implement a client class managing the MCP server process lifecycle: start the server with `subprocess.Popen` piping stdin/stdout/stderr, send JSON-RPC requests through stdin with `{"jsonrpc": "2.0", "id": 1, "method": "tools/call", "params": {"name": tool_name, "arguments": arguments}}`, read responses from stdout with readline and JSON parsing, handle errors from the response error field, and terminate cleanly with process cleanup. This subprocess pattern enables Python code to orchestrate BMAD agents without Node.js language barriers.

Error handling requires comprehensive strategies because subprocess communication introduces multiple failure modes. Define custom exception classes like `BMAdError(Exception)` with error codes for server not started, tool not found, invalid arguments, execution failed, timeout, and connection lost. Implement retry logic with exponential backoff for transient failures. Use `select.select()` on subprocess stdout with timeout to prevent indefinite blocking. Validate responses before processing to catch malformed JSON. Log all errors with full context including tool name, arguments, attempt number, and exception details. The error handling layer transforms brittle subprocess communication into a reliable integration foundation.

## Async patterns and state management

Asynchronous integration patterns leverage Python's `asyncio` for non-blocking MCP server communication. The Python MCP SDK provides async client implementations using `mcp.client.stdio.stdio_client` with `StdioServerParameters` defining the command, args, working directory, and environment variables. Wrap client creation in async context managers using `async with stdio_client(server_params) as (read, write)` and `async with ClientSession(read, write) as session`. Initialize sessions with `await session.initialize()`, list available tools with `await session.list_tools()`, call tools asynchronously with `await session.call_tool(tool_name, arguments=args_dict)`, and read resources with `await session.read_resource(resource_uri)`. Async patterns enable parallel agent invocations, concurrent task processing, non-blocking resource access, and efficient handling of multiple Moderator requests.

State management across BMAD sessions requires careful design because agents operate statelessly. Implement a `BMAdStateManager` class managing session dictionaries keyed by session ID, tracking active agent per session, maintaining task collections, and preserving context dictionaries. Use async context managers with `@asynccontextmanager` decorator to handle session lifecycle: create or restore session state on entry, start MCP server with session-specific environment variables, initialize the client connection, yield the manager for operation execution, and save session state persistently on exit. Store session state in files, databases, or Redis for production systems requiring durability across service restarts.

The context manager pattern simplifies integration complexity. Implement `async with manager.session(session_id, agent="dev") as bmad` to automatically handle server startup, session restoration, client initialization, error handling, and cleanup. Within the context, call high-level methods like `await bmad.create_task(**kwargs)` that internally track state, invoke MCP tools, update session data, and return results. This abstraction shields Moderator adapter code from low-level subprocess management while maintaining session continuity across multiple operations. Sessions can be suspended and resumed by preserving task collections and context dictionaries between invocations.

Configuration-based integration enables IDE-like interactions where Moderator appears as another interface to BMAD agents. Create MCP server configurations in JSON format with `mcpServers` object specifying command, args array, working directory, and environment variables. For Cursor integration, place configuration in `.cursor/mcp.json`. For Claude Desktop, use the application config file. The configuration includes `PYTHONPATH` pointing to the MCP server location, `OPENROUTER_API_KEY` or other model credentials, `BMAD_DEFAULT_AGENT` for default selections, and `BMAD_LOG_LEVEL` for debugging. Python code loads these configurations using YAML parsing, validates environment variables, constructs server parameters, and launches MCP servers with proper isolation and permissions.

## Complete Moderator backend adapter implementation

The Moderator backend adapter follows an abstract base class pattern enabling multiple backend implementations. Define `AgentResponse` dataclass with agent name, content string, metadata dictionary, and status field. Create `BMAdBackendAdapter(ABC)` with abstract methods `invoke_agent(agent, prompt, context)` returning AgentResponse, `create_task(task_spec)` returning task ID string, and `get_task_status(task_id)` returning status dictionary. This interface matches CCPM and Claude Code adapter patterns, enabling Moderator to swap backends transparently.

Implement `BMAdMCPAdapter(BMAdBackendAdapter)` as the concrete MCP-based implementation. The constructor accepts `server_script` path and optional `config` dictionary, initializing with `self.session = None` and `self._server_params = None`. Implement async context manager methods `__aenter__` and `__aexit__` handling server lifecycle. In `__aenter__`, create `StdioServerParameters` with command, args, and environment, launch the stdio_client transport, establish ClientSession, and initialize with `await session.initialize()`. In `__aexit__`, clean up session and transport properly even on exceptions.

The `invoke_agent` method orchestrates BMAD agent execution through MCP. Check session initialization status, call the MCP tool named "invoke_agent" with arguments containing agent identifier, prompt string, and context dictionary, await the result, parse the response extracting content and metadata fields, construct AgentResponse object with agent name, content, metadata, and status, and return the structured response. This method transforms Moderator's high-level "invoke this agent with this prompt" request into MCP tool calls that BMAD's agent system can process.

Task management methods bridge Moderator's task model and BMAD's story-based workflow. The `create_task` method maps task specifications to BMAD story creation by calling the "create_task" MCP tool with task_id, name, allocated_hours, assigned agent, and dependencies array. Return the task_id for Moderator tracking. The `get_task_status` method retrieves current task state by calling "get_task_status" with task_id and returning a dictionary with status (draft/in_progress/ready_for_review/in_review/done), hours_completed, hours_allocated, assigned_agent, and last_updated timestamp. This mapping enables Moderator to track BMAD workflows using familiar task abstractions.

Usage within Moderator workflows follows a consistent pattern. Initialize the adapter with server script path and configuration dictionary containing environment variables. Use async context manager to handle lifecycle: `async with BMAdMCPAdapter("server.py", config) as bmad`. Within the context, invoke agents sequentially (analyst for requirements analysis, PM for PRD creation, architect for system design) or in parallel where dependencies allow. Create development tasks based on planning outputs. Poll task status to monitor progress. Retrieve completed artifacts from task metadata. The adapter handles all MCP communication complexity while exposing a clean, Moderator-compatible interface.

## Advanced integration patterns and optimization

Parallel agent execution leverages asyncio task groups to invoke multiple BMAD agents simultaneously. When Moderator needs multiple perspectives (security review, performance analysis, code quality assessment), create tasks with `asyncio.create_task(bmad.invoke_agent(...))` for each agent, collect tasks in a list, await completion with `await asyncio.gather(*tasks)`, and process results in aggregate. This pattern dramatically reduces wall-clock time for multi-agent workflows while respecting that individual agents remain stateless.

Caching strategies reduce redundant BMAD invocations for frequently accessed data. Implement result caching at the adapter level using `functools.lru_cache` or external caches like Redis. Cache agent responses by hash of (agent, prompt, context) tuple with time-to-live based on content volatility—30 minutes for architecture decisions, 5 minutes for task status, no caching for story implementations. Include cache versioning keyed to BMAD framework version to invalidate caches on upgrades. Monitor cache hit rates and adjust TTLs based on observed patterns.

Streaming responses enable real-time progress visibility for long-running BMAD operations. Modify MCP server tools to yield intermediate results using async generators: `async def create_prd_stream(...)` yields progress updates as "Reading project brief", "Generating functional requirements", "Creating epic structure", and finally the complete PRD. In the adapter, implement `invoke_agent_stream` that yields AgentResponse objects with partial content and status updates. Moderator UI can display these progressive results rather than waiting for complete responses. This pattern is especially valuable for planning agents that generate large documents over minutes.

Error recovery and resilience patterns handle the inevitable failures in distributed systems. Implement circuit breakers that stop invoking failing agents after threshold failures, automatically retry with exponential backoff for transient errors, fall back to alternative agents when primary fails (analyst → PM if brainstorming fails), persist failed requests to dead letter queue for manual review, and emit detailed error events for Moderator's monitoring system. Track error rates per agent and per operation type to identify systematic issues requiring configuration adjustments or BMAD version updates.

## Testing strategies for BMAD integration

Unit testing the adapter requires mocking the MCP server communication layer. Use `unittest.mock` to create mock `ClientSession` objects with pre-configured tool responses. Test `invoke_agent` with various response formats ensuring correct AgentResponse construction. Verify error handling by having mocks raise exceptions. Test `create_task` and `get_task_status` with edge cases like missing task IDs or malformed responses. Use pytest fixtures to provide mock adapters with controlled behavior, enabling fast, isolated testing without spawning actual MCP servers.

Integration testing validates end-to-end MCP communication using a test server. Create `test_server.py` implementing FastMCP with deterministic tool responses for testing purposes—"create_task" always returns task-001, "get_task_status" returns pre-defined status progressions, "invoke_agent" returns canned responses based on agent name. Launch this test server in a subprocess during test setup. Execute real adapter methods against the test server. Verify correct request formatting, response parsing, state management, and error handling. Clean up test server subprocess in teardown. These tests catch integration issues like protocol version mismatches or serialization bugs.

End-to-end workflow testing exercises complete Moderator-BMAD interaction patterns. Implement tests simulating realistic scenarios: greenfield project (analyst → PM → architect → SM → dev → QA workflow), bug investigation (dev agent implements fix, QA reviews), feature addition (PM creates new epic, SM generates stories, parallel dev implementations), and architecture refactoring (architect redesigns component, dev updates implementation). Use pytest-asyncio for async test execution. Verify that story files are created correctly, task status progresses appropriately, agent handoffs preserve context, and final artifacts match expectations. These tests validate the integration delivers actual value to Moderator users.

Performance benchmarking identifies bottlenecks and optimization opportunities. Measure adapter initialization time (target under 1 second), tool invocation latency (target under 500ms for status checks, under 10 seconds for agent invocations), memory consumption during long-running sessions (target under 256MB), concurrent request handling capacity (target 10+ parallel agents), and end-to-end workflow duration (greenfield planning target under 2 hours). Use profiling tools to identify slow paths—subprocess communication overhead, JSON serialization bottlenecks, or context window limits. Optimize hot paths while maintaining code clarity and reliability.

## Comparison with CCPM and Claude Code

**CCPM (Critical Chain Project Management) is not an AI coding tool**—it's a traditional project management methodology from 1997 focused on resource constraints and buffer management. The proper comparison is between BMAD, Claude Code, and GitHub Spec Kit as AI-assisted development tools. Claude Code operates as a direct conversational pair programmer with low friction and high speed, ideal for quick implementations, bug fixes, and exploratory coding. It excels at understanding large existing codebases and enabling rapid iteration without upfront planning overhead. Claude Code is locked to Anthropic models (Opus, Sonnet) and provides minimal structure beyond conversation history.

BMAD represents the opposite end of the spectrum with comprehensive structure, specialized agents mimicking an entire agile team, explicit planning phases, and systematic context preservation through story files. BMAD requires significant upfront investment—30 minutes installation, 4-8 hours planning for first project, 1-2 weeks team proficiency—but delivers dramatic benefits for complex projects. Users report **2-3x development speed**, **90% reduction in rework**, and **virtually zero technical debt** when following full BMAD workflows. The framework is tool-agnostic, working with any LLM and any of 15+ supported IDEs.

GitHub Spec Kit provides a lightweight middle ground as a specification-first toolkit creating executable specifications as single source of truth. It uses simple commands (/specify, /plan, /tasks) without heavy agent orchestration, works with any AI assistant for maximum model flexibility, and focuses on separating core logic from existing code making it particularly strong for legacy modernization. Spec Kit has the lowest complexity and fastest setup but provides less structure than BMAD and fewer role-separation benefits.

Decision criteria for choosing frameworks depend on project characteristics and team preferences. Choose BMAD when project complexity justifies structure (over 10,000 lines of code), documentation has compliance or handoff value, planning prevents expensive rework, context preservation is critical across large codebases, and team benefits from clear role separation. Use Claude Code directly when speed trumps structure for immediate results, solo developer flow without handoffs, simple to moderate complexity (under 5,000 LOC), exploratory work with changing requirements, and conversational control is preferred. Consider GitHub Spec Kit when specification-first mindset already exists, tool flexibility is required, lightweight formalization provides sufficient structure, or modernizing legacy code by separating core logic.

Hybrid approaches often deliver optimal results by combining framework strengths. Use BMAD for comprehensive planning (Brief → PRD → Architecture over 4-8 hours), then export to Claude Code for rapid implementation. This provides structure without sacrificing implementation speed. Alternatively, use Spec Kit for feature specifications and invoke BMAD when specs indicate complexity requiring orchestration. For mature projects, apply BMAD to main features requiring documentation while using Claude Code direct for bug fixes and small tweaks, reducing overhead while preserving documentation value.

## Migration path from Claude Code and alternatives

Migrating from Claude Code to BMAD integration should be gradual rather than abrupt. Start by identifying the complexity threshold where Claude Code's conversational model shows strain—typically around 50+ files or when context loss becomes painful with repeated explanations. Begin using BMAD selectively for planning phases while continuing Claude Code for implementation. Run the analyst agent for requirements analysis, PM for PRD creation, and architect for system design, then hand off resulting documents to Claude Code for rapid coding. This hybrid approach provides structure benefits without forcing workflow disruption.

After initial success with planning, expand BMAD adoption to story-driven development. Let the Scrum Master generate detailed story files from the PRD and Architecture. Implement stories using Claude Code but reference BMAD story files for complete context. This preserves Claude Code's speed while leveraging BMAD's context preservation. The story files serve as comprehensive specifications preventing context loss even across sessions. Gradually introduce the BMAD Dev agent for complex stories requiring systematic implementation while keeping Claude Code for straightforward tasks.

Full BMAD adoption occurs when teams become comfortable with agent workflows and systematic handoffs. Configure BMAD in Cursor, VS Code, or Claude Code itself (BMAD supports Claude Code as an IDE) using the installer's IDE integration options. Use agent commands like `@dev *implement-story`, `@qa *review`, and `@sm *create-next-story` directly in the IDE. The transition is complete when teams naturally reach for specialized agents rather than conversational Claude Code for structured work, while still using Claude Code for rapid prototyping or quick experiments.

For teams using Cursor or GitHub Copilot, BMAD integration is complementary rather than replacement. Install BMAD in existing projects using `npx bmad-method install` and select Cursor or VS Code during IDE setup. BMAD agents appear as slash commands or @ mentions within the existing IDE experience. Continue using Copilot for inline code suggestions and quick edits while invoking BMAD agents for comprehensive planning, story creation, or systematic reviews. This layered approach provides multiple AI assistance levels matched to task complexity.

## Troubleshooting and debugging strategies

Common integration issues typically stem from subprocess communication or configuration mismatches. When the MCP server fails to start, verify Node.js version with `node --version` requiring v20+ and check `PYTHONPATH` environment variable points correctly to the server script directory. If tool calls timeout, increase timeout values from default 30 seconds to 60-120 seconds for planning agents, monitor server logs for hung processes, check for context window limits in the underlying LLM, and verify network connectivity to model APIs. If responses are malformed, validate JSON encoding with UTF-8, check for mixed stdout/stderr in subprocess pipes, and ensure proper line buffering.

Agent-specific issues often relate to configuration or document structure. When agents produce 500+ page documents, intervene early with "keep this brief, create executive summary with references to supporting documents", adjust agent personas to emphasize concision, and implement manual review checkpoints during long document generation. When Dev agents select wrong stories, always specify exact story filename like `*implement-story docs/stories/1.1.story.md` rather than relying on automatic selection, verify story status is not "Draft" (Dev won't work on drafts), and ensure previous story is marked "Done" for sequential workflows.

Context window exhaustion manifests as incomplete responses, repeated information, or agent confusion. Monitor token consumption using IDE metrics or LLM API dashboards. Reduce context by enabling document sharding with `prdSharded: true` and `architectureSharded: true` in core-config, minimize `devLoadAlwaysFiles` to only essential documents under 10KB each, break large stories into smaller focused stories, and use course corrections that summarize progress and reset context. Switch to larger context models (Claude Opus 200K, Gemini Pro 2M) for planning phases accepting higher costs.

Workflow blockages require understanding BMAD's isolation model. When information doesn't flow between agents, manually create "Handoff Prompts" sections in PRD and Architecture containing context about current feature, dependencies, and status. Add cross-references in story files pointing to relevant technical analysis documents. Use the orchestrator agent with `@bmad-orchestrator` to query workflow state. Review agent activation traces ensuring all mandatory checkpoints complete (read core-config, load devLoadAlwaysFiles, confirm steps before proceeding). The user must actively coordinate isolated agents since they share no memory or state.

## Performance optimization and scalability

Optimizing Moderator-BMAD integration performance requires attention to multiple layers. At the MCP server level, implement connection pooling to avoid repeated subprocess creation overhead—maintain a pool of 3-5 running servers and distribute requests across the pool. Use persistent server mode where servers remain running between requests rather than starting/stopping for each operation. Implement request queuing to prevent server overload when Moderator receives burst traffic. Monitor server process health and automatically restart crashed servers. These optimizations reduce cold start latency from 5-10 seconds to under 500ms.

Document structure profoundly impacts agent performance. Enable sharding for all large documents following BMAD's recommended patterns—PRD sharded into epic-specific files under 5,000 words each, Architecture sharded into component modules under 3,000 words, and stories sharded with one file per user story. Keep `devLoadAlwaysFiles` focused on truly always-needed context (coding standards, tech stack) rather than comprehensive documentation. Create summary documents with references to detailed documents rather than embedding everything. Well-structured documentation reduces per-agent token consumption by 60-80% while improving response quality.

Agent invocation patterns affect system throughput. Identify parallelizable operations where multiple agents analyze different aspects simultaneously—security review, performance analysis, and code quality can run concurrently. Avoid sequential dependencies where possible by providing complete context to agents upfront. Cache frequently requested information like available agents list, project configuration, and task status for completed tasks. Use batch operations to create multiple stories or tasks in single invocations. Strategic parallelization and caching reduce end-to-end workflow duration from hours to tens of minutes.

Resource management prevents runaway costs and system degradation. Implement request rate limiting per user or per tenant with quotas like 100 agent invocations per hour. Set timeout policies terminating operations exceeding thresholds (5 minutes for status checks, 30 minutes for planning agents). Monitor LLM API costs with alerts at 80% of budget. Use cheaper models (Sonnet instead of Opus, Gemini Flash instead of Pro) for routine operations reserving expensive models for complex planning. Implement circuit breakers stopping agent invocations when error rates exceed 20%. These controls maintain system stability while optimizing cost efficiency.

## Security considerations and best practices

BMAD integration introduces security considerations beyond traditional Python services. Agent operations execute with the permissions of the MCP server process, accessing filesystem, environment variables, and network APIs. Run MCP servers with least-privilege principles using dedicated service accounts with minimal permissions. Implement filesystem restrictions limiting agents to project directories rather than full system access. Use environment variable filtering to expose only necessary credentials to MCP servers. Isolate server processes using containers or virtual environments preventing lateral movement in case of compromise.

Input validation and sanitization prevent injection attacks through agent prompts. Validate all user inputs before including in prompts—reject inputs containing obvious prompt injection attempts like "ignore previous instructions", sanitize file paths to prevent directory traversal attacks, validate task IDs match expected format before lookups, and limit prompt length to reasonable maximums (10,000 characters for user prompts). Implement output validation checking agent responses for sensitive information leakage like API keys, database credentials, or internal URLs before returning to Moderator. Log all validation failures for security monitoring.

LLM API security requires protecting credentials and managing data privacy. Store API keys in secure vaults (HashiCorp Vault, AWS Secrets Manager) rather than environment variables or config files. Rotate API keys quarterly and immediately upon employee departures. Understand data retention policies of LLM providers—some retain prompts and completions for training, others offer zero retention options. For sensitive projects, use on-premises LLM deployments or providers with contractual data isolation guarantees. Audit LLM API calls logging prompts, completions, token counts, and timestamps for compliance requirements.

Agent guardrails prevent potentially harmful operations. Implement a validation layer checking agent-generated code for dangerous patterns—system command execution without input sanitization, file operations on absolute paths outside project, network requests to non-whitelisted domains, and database queries without parameterization. Use static analysis tools to scan generated code before execution. For critical operations (production deployments, database migrations, security changes), require multi-LLM consensus where 2-3 different models generate solutions and a judge LLM selects the best while flagging significant disagreements. This defense-in-depth approach mitigates single-model hallucinations and adversarial prompt injections.

## Sample backend adapter with complete implementation

The production-ready BMAD adapter requires comprehensive error handling, logging, metrics, and configuration management. Begin with a complete imports section including asyncio for async patterns, subprocess for MCP server management, json for request/response serialization, logging for observability, dataclasses for structured data, typing for type hints, functools for caching, and contextlib for async context managers. Define configuration as a dataclass with server_script path, environment dict, timeout_seconds integer, max_retries integer, log_level string, and enable_caching boolean. Initialize logging with structlog or standard logging configured for JSON output.

Implement AgentResponse and TaskSpecification dataclasses providing clean interfaces. AgentResponse contains agent string, content string, metadata dict, status string, tokens_used integer, duration_seconds float, and timestamp datetime. TaskSpecification contains task_id string, name string, description string, allocated_hours float, assigned_agent string, dependencies list, priority integer, and due_date optional datetime. These structures decouple Moderator's data model from BMAD's internal representations enabling independent evolution.

The adapter implementation manages complex lifecycle and state. Initialize with server script path and configuration dict, validate configuration checking required fields, setup logging with correlation IDs, initialize metrics collectors (Prometheus, StatsD), create session manager for state tracking, and initialize connection pool for MCP servers. Implement `__aenter__` starting server pool, health checking all servers, setting up signal handlers for graceful shutdown, and returning self. Implement `__aexit__` stopping ongoing operations with grace period, persisting session state to storage, collecting final metrics, stopping server pool, and ensuring complete cleanup even on exceptions.

Tool invocation methods provide the core adapter functionality. The `invoke_agent` method accepts agent, prompt, context, and optional timeout_override; selects server from pool using round-robin; constructs MCP tool call with agent configuration, prompt text, and context dictionary; sends request with timeout; handles retries on transient failures; parses response extracting content and metadata; records metrics for duration, tokens, and success/failure; logs invocation with correlation ID; constructs and returns AgentResponse. Include comprehensive error handling catching subprocess errors, JSON decode errors, timeout errors, and unexpected exceptions, wrapping in BMAdError with detailed context.

Task management methods bridge Moderator workflows and BMAD story files. The `create_task` method accepts TaskSpecification, maps to BMAD story structure with epic number derived from dependencies, story number as next available, content from task description with acceptance criteria, and dev notes with implementation guidance. Call MCP "create_story" tool with mapped parameters, await response, extract created story file path, update session state tracking task, record creation metrics, and return task ID. The `get_task_status` method reads story file through MCP "read_story" tool, parses status from YAML frontmatter, extracts completion percentage from dev notes, calculates remaining hours, and returns structured status dictionary.

Advanced features enhance production reliability. Implement metrics collection recording operation counts, latencies (p50, p95, p99), error rates by type, token consumption, and concurrent operation counts. Export metrics to Prometheus with labels for agent, operation, status. Add health check endpoint returning server pool status, queue depth, error rate, and available capacity. Implement graceful degradation disabling non-critical features when under high load. Add request prioritization giving interactive operations higher priority than batch jobs. Include circuit breakers stopping unhealthy servers after threshold failures. Log structured events with correlation IDs enabling distributed tracing across Moderator, adapter, MCP servers, and LLM APIs.

Configuration management supports multiple environments and tenant isolation. Load base configuration from YAML files in `config/bmad-base.yaml` defining default settings. Override with environment-specific configs in `config/bmad-{env}.yaml` for development, staging, production. Support tenant-specific overrides in database or configuration service enabling per-customer model selection, rate limits, and feature flags. Implement configuration hot-reloading watching config files for changes and updating running adapter without restart. Validate configuration on load checking required fields, type correctness, and constraint satisfaction preventing misconfigurations from reaching production.

## Conclusion and next steps

BMAD integration with Moderator requires understanding fundamentally different architectural patterns than traditional backend engines. Rather than importing a library and calling methods, integration proceeds through MCP servers exposing BMAD's agent methodology as protocol-based tools. The subprocess communication layer, async patterns, state management, and error handling create a reliable bridge between Python orchestration and Node.js agent execution. This guide provides complete patterns for production-ready integration including backend adapters, error handling, testing strategies, performance optimization, and security considerations.

The implementation path begins with installing BMAD using `npx bmad-method install`, setting up Python MCP server with FastMCP, implementing the backend adapter following patterns in this guide, writing comprehensive tests covering unit, integration, and end-to-end scenarios, and deploying with monitoring for metrics, logs, and alerts. Start with pilot projects testing BMAD integration on non-critical workloads, measure actual benefits comparing development speed and code quality against Claude Code baselines, gather user feedback on workflow friction and documentation value, and iterate adapter implementation based on production learnings.

BMAD excels for complex projects requiring comprehensive documentation, systematic planning, context preservation across large codebases, compliance audit trails, and team collaboration with role separation. It delivers measurable benefits—2-3x development speed, 90% rework reduction, virtually zero technical debt—when used for appropriate workloads. However, BMAD introduces significant overhead for simple tasks making it unsuitable for quick bug fixes or exploratory prototyping. Moderator users benefit from intelligent backend selection where simple requests route to Claude Code for speed while complex projects leverage BMAD's systematic approach.

Future enhancements to the adapter should focus on improving observability with detailed agent execution traces, implementing semantic caching to recognize similar requests across different phrasing, adding support for BMAD expansion packs enabling domain-specific capabilities, creating simplified onboarding workflows reducing the steep learning curve, and developing monitoring dashboards visualizing agent workflows, context consumption, and quality metrics. The BMAD ecosystem continues evolving rapidly with v6-alpha introducing major architectural changes, suggesting ongoing adapter maintenance will be required as the framework matures and gains wider adoption.